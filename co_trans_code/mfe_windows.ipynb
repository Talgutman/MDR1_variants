{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c61e65-c004-4b7e-aa0e-038229dd00e1",
   "metadata": {},
   "source": [
    "In this notebook we calculate the minimum free energy (mfe) of 39 long sliding windows for a CDS. \n",
    "A single CDS has X orthologs. and each ortholog has 200 randomizations (100 column, 100 vertical). We perform the mfe sliding window calculation for all of these. \n",
    "\n",
    "We will do the following:\n",
    "1. Download the sequences (both original and randomized MSAs of the gene)\n",
    "2. Preprocess the sequences as needed for the mfe calulation (DNA to RNA, remove deletions). \n",
    "3. Find invalid windows: some of our sequences contain ambigous alphabet (such as \"N\", positions where we do not know the nts). *the mfe of windows containing ambigious alphabet will be nan.* \n",
    "4. Calculate mfe per window for all valid windows, for both original sequences and randomizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f4823d-d4af-4a2c-98b6-badb06860c02",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172f34f1-a5f9-4d81-8599-9617d630c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import io\n",
    "import RNA #the ViennaRNA package\n",
    "from Bio import SeqIO, AlignIO\n",
    "import gzip\n",
    "import concurrent.futures\n",
    "import time\n",
    "import re\n",
    "from Utils_Tal import aa_positions_to_nt_positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5a839-59ce-43d6-b07f-c7f75bc3a489",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa5419f-401e-4fbf-8596-f7cac7656f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function recieves the alignment in nucleotides and returns the alignment in codons'''\n",
    "def get_original_codons_array(alignment_NT) -> np.ndarray:\n",
    "    #create codon array from nucleotide array\n",
    "    nuc_array = np.array(alignment_NT) # an array where each column is a nucleotide position\n",
    "    #lets merge every three columns into one, to obtain a numpy of codon positions instead of nucleotide positions\n",
    "    codons_array = np.zeros((nuc_array.shape[0],nuc_array.shape[1]//3),dtype=object)\n",
    "    for col in range(0,nuc_array.shape[1],3):\n",
    "        merged_to_codon = np.char.add(np.char.add(nuc_array[:,col],nuc_array[:,col+1]),nuc_array[:,col+2]) \n",
    "        codons_array[:,col//3] = merged_to_codon\n",
    "    return(codons_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0747b9a-b446-42aa-af81-6afc7e3dfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function recreates the randomizations. In order to save memory we only saved the original msa \n",
    "and a dictionary with the location of the differences of each randomization and the original msa. \n",
    "There are two keys in the dictionary:\n",
    "1. 'locations': the locations of the differences in the msa\n",
    "2. 'codons': the codons in the randomization in these locations'''\n",
    "\n",
    "def get_randomized_codons_array(randomization_path:str, original_codons_array:np.ndarray, num_rands:int) -> np.ndarray:\n",
    "    diff_dict = pd.read_pickle(randomization_path)\n",
    "    rand = original_codons_array.copy()\n",
    "    rand = np.tile(rand, (num_rands, 1, 1))\n",
    "    rand[diff_dict['locations']] = diff_dict['codons']\n",
    "    return(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a558c0c-24f3-45bb-8c2e-7f159cf7835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function receives a sequence, processes it to fit the mfe calculation and returns its deletion positions, the length\n",
    "after preprocessing and the processed sequence.\n",
    "'''\n",
    "def preprocess_original_sequence(sequence:np.ndarray) -> (str,int,list):\n",
    "    #get locations of deletions of original sequence:\n",
    "    del_locs_aa = np.where(sequence == '---')[0]\n",
    "    del_locs_nt = aa_positions_to_nt_positions(del_locs_aa)\n",
    "    #preprocess original sequence (dna to rna, remove dels, make sure capital letters only)\n",
    "    sequence = ''.join(sequence).replace(\"-\",\"\").replace(\"T\",\"U\").upper()\n",
    "    len_sequence = len(sequence) #original sequence length, without deletions and without the stop codon. \n",
    "    return(sequence,len_sequence,del_locs_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55f060b-079f-4e23-b93f-33145808e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Our sequences contain invalid alphabet such as N (a position that could be A/C/G/U). We do not calculate the mfe for windows\n",
    "containing ambigious characters. This functions takes a single sequence (str) and returns a list of the valid windows - the windows\n",
    "with no ambigiuos characters, for which we will calculate the mfe score.'''\n",
    "def find_valid_windows(sequence:str, window_size:int, valid_chars:set) -> list:\n",
    "    num_windows = len(sequence) - window_size + 1\n",
    "    valid_windows = []\n",
    "    for window in range(num_windows):\n",
    "        cur_window_seq = sequence[window:window+window_size]\n",
    "        if len(set(cur_window_seq) - valid_chars) == 0: #meaning: if there are no ambigious alphabet\n",
    "            valid_windows.append(window)\n",
    "    return(valid_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af4eb20-c17a-4d23-b03e-59525942bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function calculates the MFE of all 39 nt-long windows in a given sequence '''\n",
    "def calc_mfe_single_sequence(sequence:str, max_num_windows:int, window_size:int, valid_windows:list) -> np.ndarray:\n",
    "    num_windows = len(sequence) - window_size + 1\n",
    "    \n",
    "    #initialize results vector\n",
    "    mfe_single_seq = np.empty((1,max_num_windows))\n",
    "    mfe_single_seq[:] = np.nan\n",
    "    #iterate over windows and calculate mfe\n",
    "    for window in valid_windows:\n",
    "        assert(len(sequence[window:window+window_size]) == 39)\n",
    "        (_, mfe) = RNA.fold(sequence[window:window+window_size])\n",
    "        mfe_single_seq[0,window] = mfe\n",
    "    return(mfe_single_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1859cc5c-528c-43ed-86d4-3778d9c6c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculates the MFE per window scores for the original CDS sequences of all orthologs '''\n",
    "def calc_mfe_original(sequences:list, gene:str, num_orthologs:int, max_num_windows:int, window_size:int, valid_windows:list) -> None:\n",
    "    mfe_results = np.empty((num_orthologs,max_num_windows)) #initilize results matrix\n",
    "    mfe_results[:] = np.nan\n",
    "\n",
    "    for cur_ortholog in range(num_orthologs):\n",
    "        mfe_results[cur_ortholog,:] = calc_mfe_single_ortholog_sequence(sequences[cur_ortholog], max_num_windows, window_size,valid_windows[cur_ortholog])\n",
    "    return(mfe_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f772b9d-ab9f-402e-a3c0-d6673d1cb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Zip and save the window mfe scores for the original MSA and the randomized MSAs '''\n",
    "def zip_and_save_results(gene:str, mfe_orig:np.ndarray, mfe_col:np.ndarray, mfe_ver:np.ndarray) -> None:\n",
    "    output_path = f\"../Results/AllGenes/mfe/window_mfe_scores/original/{gene}.pickle\"\n",
    "    with open(output_path, 'wb') as handle:\n",
    "        pickle.dump(mfe_orig, handle, protocol = 4)\n",
    "    #zip it\n",
    "    !gzip $output_path\n",
    "\n",
    "    output_path = f\"../Results/AllGenes/mfe/window_mfe_scores/column/{gene}.pickle\"\n",
    "\n",
    "    with open(output_path, 'wb') as handle:\n",
    "        pickle.dump(mfe_col, handle, protocol = 4)\n",
    "    #zip it\n",
    "    !gzip $output_path\n",
    "\n",
    "    output_path = f\"../Results/AllGenes/mfe/window_mfe_scores/vertical/{gene}.pickle\"\n",
    "    with open(output_path, 'wb') as handle:\n",
    "        pickle.dump(mfe_ver, handle, protocol = 4)\n",
    "    #zip it\n",
    "    !gzip $output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7932a3e-a06f-45d3-8630-64cda79c0adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Calculate the MFE per window scores for the original and permutated MSAs, for a single gene ''' \n",
    "\n",
    "def calc_mfe_windows_single_gene(gene:str, num_randomizations:int, window_size:int) -> None:\n",
    "    try:\n",
    "\n",
    "        ''' (1) Download data'''\n",
    "        #original MSA in nucleotides - unzip and read alignment\n",
    "        path_NT = f\"../co_trans_data/orthologs/nt_after_msa/{gene}.fasta.gz\" #MSA in nucleotides\n",
    "        local_path = f\"./{gene}.fasta\"\n",
    "        !gzip -c -d $path_NT > $local_path #unzip without erasing the zipped version\n",
    "        alignment_NT = AlignIO.read(local_path, \"fasta\")\n",
    "        codons_array = get_original_codons_array(alignment_NT)\n",
    "        os.remove(local_path)\n",
    "\n",
    "        #randomizations\n",
    "        path_col_rand = f\"../Results/AllGenes/column_permutations/{gene}.pickle.gz\" #MSA in nucleotides\n",
    "        codons_array_col = get_randomized_codons_array(path_col_rand, codons_array, num_randomizations)\n",
    "        path_ver_rand = f\"../Results/AllGenes/vertical_permutations/{gene}.pickle.gz\" #MSA in nucleotides\n",
    "        codons_array_ver = get_randomized_codons_array(path_ver_rand, codons_array, num_randomizations)\n",
    "\n",
    "        ''' (2) Preprocess original and random sequences and get needed info (sequence lengths, deletion locations...).\n",
    "        Preprocessing includes: transcribing, removing deletions, asserting capital letters. '''\n",
    "        num_orthologs = codons_array_col.shape[1]\n",
    "        #preprocess original\n",
    "        len_sequences_dict,deletion_pos_dict,original_sequences,len_sequences = {}, {}, [], [] # we need this for \"find_significant_folding_positions.ipynb\"\n",
    "        for cur_ortholog in range(num_orthologs) :\n",
    "            processed_seq, length_seq, dels = preprocess_original_sequence(codons_array[cur_ortholog,:])\n",
    "            len_sequences_dict[cur_ortholog] = length_seq\n",
    "            deletion_pos_dict[cur_ortholog] = dels\n",
    "            original_sequences.append(processed_seq)\n",
    "            len_sequences.append(length_seq)\n",
    "        #save dicts needed for \"mfe_positions_zscores.ipynb\"\n",
    "        with open(f\"../co_trans_data/cds_lengths/{gene}.pickle\", 'wb') as handle:\n",
    "            pickle.dump(len_sequences_dict, handle)\n",
    "        with open(f\"../co_trans_data/del_positions_orig/{gene}.pickle\", 'wb') as handle:\n",
    "            pickle.dump(deletion_pos_dict, handle)\n",
    "        #preprocess randomizations\n",
    "        rand_sequences_dict = {} #will hold the random sequences after preprocessing\n",
    "        rand_sequences_dict['column'] = {}\n",
    "        rand_sequences_dict['vertical'] = {}\n",
    "\n",
    "        for rand in range(num_randomizations):\n",
    "            rand_sequences_dict['column'][rand] = {}\n",
    "            rand_sequences_dict['vertical'][rand] = {}\n",
    "            for cur_ortholog in range(num_orthologs):\n",
    "                #column\n",
    "                sequence = codons_array_col[rand,cur_ortholog,:]\n",
    "                rand_sequences_dict['column'][rand][cur_ortholog] = ''.join(sequence).replace(\"-\",\"\").replace(\"T\",\"U\").upper()\n",
    "                #vertical\n",
    "                sequence = codons_array_ver[rand,cur_ortholog,:]\n",
    "                rand_sequences_dict['vertical'][rand][cur_ortholog] = ''.join(sequence).replace(\"-\",\"\").replace(\"T\",\"U\").upper()\n",
    "\n",
    "        ''' (3) Finding valid windows: windows that do not contain any ambigious alphabet.\n",
    "        The locations of the ambigious alphabet are the same between the original and the randomized msas, \n",
    "        so we will find the valid windows only once, using the original msa, and use it for all sequences.'''\n",
    "\n",
    "        valid_windows = [None]*num_orthologs #an empty list of size \"num_orthologs\", will hold the valid windows of each ortholog\n",
    "        valid_chars = {'A','C','G','U'}\n",
    "        for cur_ortholog in range(num_orthologs):\n",
    "            valid_windows_cur_ortholog = find_valid_windows(original_sequences[cur_ortholog], window_size, valid_chars)\n",
    "            valid_windows[cur_ortholog] = valid_windows_cur_ortholog\n",
    "\n",
    "        ''' (4) Calculate mfe per window for all valid windows, for both original sequences and randomizations '''\n",
    "        max_num_windows = max(len_sequences) - window_size + 1 \n",
    "        #original\n",
    "        mfe_orig = np.empty((num_orthologs,max_num_windows)) #initilize results matrix\n",
    "        mfe_orig[:] = np.nan\n",
    "        for cur_ortholog in range(num_orthologs):\n",
    "            mfe_orig[cur_ortholog,:] = calc_mfe_single_sequence(original_sequences[cur_ortholog], max_num_windows, window_size,valid_windows[cur_ortholog])\n",
    "        #column\n",
    "        mfe_col = np.empty((num_randomizations,num_orthologs,max_num_windows)) #initilize results matrix\n",
    "        mfe_col[:] = np.nan\n",
    "        mfe_ver = mfe_col.copy()\n",
    "        for cur_rand in range(num_randomizations):\n",
    "            for cur_ortholog in range(num_orthologs):\n",
    "                mfe_col[cur_rand,cur_ortholog,:] = calc_mfe_single_sequence(rand_sequences_dict['column'][cur_rand][cur_ortholog], max_num_windows, window_size,valid_windows[cur_ortholog])\n",
    "                mfe_ver[cur_rand,cur_ortholog,:] = calc_mfe_single_sequence(rand_sequences_dict['vertical'][cur_rand][cur_ortholog], max_num_windows, window_size,valid_windows[cur_ortholog])\n",
    "\n",
    "        zip_and_save_results(gene, mfe_orig, mfe_col, mfe_ver)\n",
    "        \n",
    "    except Exception as e:\n",
    "        file_object = open(f\"../Results/AllGenes/mfe/window_mfe_scores/error_window_mfe.txt\", 'a')\n",
    "        file_object.write(f\"gene {gene} failed with error: {e}\")\n",
    "        file_object.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f7a5d-2049-4b9c-8709-2b1cf332a35d",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158c33f3-7e8b-498f-81d1-8037ca465714",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_list = pd.read_pickle(\"../co_trans_data/genes_with_rands.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04dba218-5f99-42cb-8b15-c3cd63c39b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create batches of genes'''\n",
    "num_wanted_cpus = 30\n",
    "num_genes = len(genes_list)\n",
    "num_genes_per_batch = int(np.round(num_genes /num_wanted_cpus))\n",
    "batches_of_genes = [genes_list[x:x+num_genes_per_batch] for x in range(0, num_genes, num_genes_per_batch)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e9b1c0-ce65-4664-a7e2-4aed04efb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function calls our main function \"get_significant_cai_positions_single_gene\" for  batch of genes'''\n",
    "def do_for_single_batch(single_batch_genes: list, num_randomizations:int, window_size:int) -> None:\n",
    "    for gene in single_batch_genes:\n",
    "        calc_mfe_windows_single_gene(gene, num_randomizations, window_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a40e64-d27c-4e0d-aeed-f5d2bf561a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Run parallely '''\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for single_batch in batches_of_genes:\n",
    "        futures.append(executor.submit(do_for_single_batch, single_batch_genes = single_batch, num_randomizations = 101, window_size = 39))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6048d3-9ac4-4b40-b42c-4ff69280b432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
